{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will explain the how my Python script \"digitrec.py\" works and its preformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pre\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the imports I used for my script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is initialise the network. I used the sequential model, this means we can add layers to the initialised network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "model = kr.models.Sequential()\n",
    "#Build neural network \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to add the layers, I added three layers. 1000, 750 and 512. I set the activation function as ReLu. To determine which class to output, I used the SoftMax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 3 layers (1000, 750, 512)\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=750, activation='relu'))\n",
    "model.add(kr.layers.Dense(units=512, activation='relu'))\n",
    "\n",
    "# Compile model - Adam optimizer for our model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Add 10 output neurons, one for each\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 750)               750750    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               384512    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,920,262\n",
      "Trainable params: 1,920,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123ki\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# input, output and hidden layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used gzip to unzip all the training, testing images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the files\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_images = f.read()\n",
    "    \n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_labels = f.read()\n",
    "    \n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    training_images = f.read()\n",
    "    \n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    training_labels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files and save to memory\n",
    "training_images = ~np.array(list(training_images[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "training_labels =  np.array(list(training_labels[8:])).astype(np.uint8)\n",
    "\n",
    "test_images = ~np.array(list(test_images[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_labels = np.array(list(test_labels[8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and Lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must put each pixel into a corrisponding neuron in the inputs of the network, we have to flatten the datasets into single arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the array , 784 neurons\n",
    "inputs = training_images.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up the lables, we must encode the data and then turn all the label dataset into binary values in a 10x10 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that every thing is set up we can run the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user will firs be greeted with a message asking what they would like to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------Welcome---------------------------------\")\n",
    "print(\"Would you like to train a dataset? Or load the data you have?\")\n",
    "print(\"Enter Y to train data set\")\n",
    "print(\"Enter N to load your own data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user presses y they will proceed to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.0776 - acc: 0.9723\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.0408 - acc: 0.9854\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.0323 - acc: 0.9887\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0268 - acc: 0.9906\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0246 - acc: 0.9915\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0215 - acc: 0.99261s - los\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0200 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0174 - acc: 0.9940\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0166 - acc: 0.9943\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0155 - acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a1b28ec18>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we ca see neural network is working, We will now test it manually to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "The actual number:   [3]\n",
      "The network reads:   [3]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [1]\n",
      "The network reads:   [1]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [4]\n",
      "The network reads:   [4]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [5]\n",
      "The network reads:   [5]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [1]\n",
      "The network reads:   [1]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [2]\n",
      "The network reads:   [2]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [0]\n",
      "The network reads:   [0]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [9]\n",
      "The network reads:   [9]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [9]\n",
      "The network reads:   [9]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "The actual number:   [9]\n",
      "The network reads:   [9]\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "  from random import randint\n",
    "    \n",
    "for i in range(10): #Run 10 tests\n",
    "        print(\"----------------------------------\")\n",
    "        randIndex = randint(0, 9999) #Get a random index to pull an image from\n",
    "        test = model.predict(test_images[randIndex:randIndex+1]) #Pull the image from the dataset\n",
    "        result = test.argmax(axis=1) #Set result to the highest array value\n",
    "        print(\"The actual number:  \", test_labels[randIndex:randIndex+1])\n",
    "        print(\"The network reads:  \", result)\n",
    "        print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it is working very accurately. We will now test the metrics accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.0157480381850192, 0.994444995689392]\n"
     ]
    }
   ],
   "source": [
    " #print out accuracy\n",
    "    metrics = model.evaluate(inputs, outputs, verbose=0)\n",
    "    print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Error Rate %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.56%\n",
      "9665\n"
     ]
    }
   ],
   "source": [
    "  # Evaluates and then prints error rate accuracy\n",
    "    scores = model.evaluate(inputs, outputs, verbose=2)\n",
    "    print(\"Error Rate: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I think this script is fairly accurate and quite well put together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "- https://medium.com/coinmonks/handwritten-digit-prediction-using-convolutional-neural-networks-in-tensorflow-with-keras-and-live-5ebddf46dc8\n",
    "- https://www.tensorflow.org/tutorials/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
